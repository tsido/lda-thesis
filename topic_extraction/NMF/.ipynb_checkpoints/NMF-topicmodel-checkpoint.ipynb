{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf93f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        welcome land fairies puzzle game toddlers kids...\n",
       "1        interactive fantasy adventure book game rpg ga...\n",
       "2        theres plenty press touch explore children age...\n",
       "3        theres plenty press touch explore children age...\n",
       "4        winner xyzzy interactive fiction awards best p...\n",
       "                               ...                        \n",
       "13169    new season finally field outmanoeuvre defender...\n",
       "13170    vacation usa explore beautiful travel spots me...\n",
       "13171    number 1 casino slot machine doesnt real play ...\n",
       "13172    xairports utility app allows owners popular fl...\n",
       "13173    esta aplicaci√≥n es uso exclusivo para salones ...\n",
       "Name: TrimmedDescription, Length: 13174, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate topics for documents using NMF \n",
    "\n",
    "# Inspired by NMF topic modelling tutorial at https://www.kaggle.com/code/rockystats/topic-modelling-using-nmf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# trim the vocabulry with stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# read in the document data\n",
    "df = pd.read_csv('../enriched_data.csv')\n",
    "\n",
    "\n",
    "# NMF preprocessing functions\n",
    "def clean_whitespace(row):\n",
    "    word_array = row.split()\n",
    "    trimmed_row = ' '.join(word_array)\n",
    "    return trimmed_row\n",
    "\n",
    "def strip_punctuation(row):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    trimmed_row = row.translate(translator)\n",
    "    return trimmed_row\n",
    "\n",
    "def lowercase(row):\n",
    "    return row.lower()\n",
    "\n",
    "def remove_stop_words(row):\n",
    "    word_array = row.split()\n",
    "    trimmed_row = ' '.join([word for word in word_array if word not in ENGLISH_STOP_WORDS])\n",
    "    return trimmed_row\n",
    "\n",
    "\n",
    "# combine separate preprocessing steps\n",
    "def preprocess(row):\n",
    "    trimmed_row = strip_punctuation(row)\n",
    "    trimmed_row = clean_whitespace(trimmed_row)\n",
    "    trimmed_row = lowercase(trimmed_row)\n",
    "    trimmed_row = remove_stop_words(trimmed_row)\n",
    "    return trimmed_row\n",
    "\n",
    "\n",
    "# TrimmedDescriptions will be used to construct the document matrix for\n",
    "# NMF\n",
    "df['TrimmedDescription'] = df['Description'].apply(preprocess)\n",
    "\n",
    "documents = df['TrimmedDescription']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b3d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=3,        #don't add terms that appear less than 3 of the descriptions to the vocabulary\n",
    "    max_features=5000, # limit to 5000 most frequent terms\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "tfidf_vocabulary = vectorizer.fit_transform(documents)\n",
    "tfidf_word_id_map = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e2e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the non-negative matrix factorization\n",
    "# TODO: explore the number of topics we want\n",
    "nmf = NMF(\n",
    "    n_components=30, # number of topics to generate\n",
    "    init='nndsvd'\n",
    ").fit(tfidf_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eed700e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'game fun simple addictive great',\n",
       " 1: 'word words letters letter search',\n",
       " 2: 'cards card deck suit pile',\n",
       " 3: 'kids learning fun educational learn',\n",
       " 4: 'fish big discover games enjoy',\n",
       " 5: 'subscription period account charged current',\n",
       " 6: 'puzzles puzzle jigsaw pieces solve',\n",
       " 7: 'play players player friends online',\n",
       " 8: 'battle enemies weapons world fight',\n",
       " 9: 'slots casino slot vegas win',\n",
       " 10: 'car racing cars race tracks',\n",
       " 11: 'solitaire spider klondike games freecell',\n",
       " 12: 'app tabtale privacy make use',\n",
       " 13: 'blocks color block coloring mode',\n",
       " 14: 'sudoku numbers number notes grid',\n",
       " 15: 'bubble bubbles pop shooter blast',\n",
       " 16: 'tiles mahjong tile board remove',\n",
       " 17: 'chess moves board pieces mate',\n",
       " 18: 'iphone ipad touch ipod app',\n",
       " 19: 'truck garbage trucks monster vehicles',\n",
       " 20: 'escape room objects hidden solve',\n",
       " 21: 'ball balls bowling soccer physics',\n",
       " 22: 'questions quiz trivia guess knowledge',\n",
       " 23: 'dice roll rolls yatzy points',\n",
       " 24: 'tap jump screen score avoid',\n",
       " 25: 'animals animal farm zoo cute',\n",
       " 26: 'levels level difficulty challenging challenge',\n",
       " 27: 'poker texas chips holdem video',\n",
       " 28: 'children child scene learning app',\n",
       " 29: 'en el la que para'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a df with each topic by document\n",
    "H_doc_by_topic = nmf.transform(vectorizer.transform(documents))\n",
    "\n",
    "n_topic_words = 5\n",
    "\n",
    "topics = {}\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    t = (topic_idx)\n",
    "    topics[t] = ' '.join([tfidf_word_id_map[i] for i in topic.argsort()[:(-n_topic_words - 1): -1]])\n",
    "\n",
    "topics\n",
    "\n",
    "# Transform H_doc_by_topic so that it contains the actual topic[i] \n",
    "# as well as the probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3344b813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kids learning fun educational learn',\n",
       " 'puzzles puzzle jigsaw pieces solve',\n",
       " 'game fun simple addictive great']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO get list of topics for documents\n",
    "# get top 3 scoring topics\n",
    "[topics[i] for i in docweights[0].argsort()[::-1][:3]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[['Topic_1', 'Topic_2','Topic_3']] =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48144b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
